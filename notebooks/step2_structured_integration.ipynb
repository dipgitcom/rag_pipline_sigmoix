{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb288a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ea13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "openai.api_key = \"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\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredDataProcessor:\n",
    "    \"\"\"Extract and process structured data (tables) from financial PDFs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tables = []\n",
    "        self.financial_keywords = [\n",
    "            'revenue', 'income', 'expense', 'profit', 'loss', 'assets', 'liabilities',\n",
    "            'equity', 'cash', 'debt', 'margin', 'growth', 'earnings', 'ebitda'\n",
    "        ]\n",
    "    \n",
    "    def extract_tables_from_pdf(self, pdf_path: str) -> List[pd.DataFrame]:\n",
    "        \"\"\"Extract tables using multiple methods for robustness\"\"\"\n",
    "        all_tables = []\n",
    "        \n",
    "        print(\"Extracting tables using pdfplumber...\")\n",
    "        # Method 1: pdfplumber (best for simple tables)\n",
    "        try:\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    tables = page.extract_tables()\n",
    "                    for table_idx, table in enumerate(tables):\n",
    "                        if table and len(table) > 1:  # Has header + data\n",
    "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                            df['source_page'] = page_num + 1\n",
    "                            df['table_id'] = f\"pdfplumber_p{page_num+1}_t{table_idx+1}\"\n",
    "                            df['extraction_method'] = 'pdfplumber'\n",
    "                            all_tables.append(df)\n",
    "            \n",
    "            print(f\"pdfplumber extracted {len(all_tables)} tables\")\n",
    "        except Exception as e:\n",
    "            print(f\"pdfplumber extraction failed: {e}\")\n",
    "        \n",
    "        # Method 2: tabula-py (good for complex tables)\n",
    "        print(\"Extracting tables using tabula...\")\n",
    "        try:\n",
    "            tabula_tables = tabula.read_pdf(\n",
    "                pdf_path, \n",
    "                pages='all',\n",
    "                multiple_tables=True,\n",
    "                pandas_options={'header': 0}\n",
    "            )\n",
    "            \n",
    "            for idx, df in enumerate(tabula_tables):\n",
    "                if not df.empty and len(df) > 1:\n",
    "                    df['table_id'] = f\"tabula_t{idx+1}\"\n",
    "                    df['extraction_method'] = 'tabula'\n",
    "                    all_tables.append(df)\n",
    "            \n",
    "            print(f\"tabula extracted {len(tabula_tables)} additional tables\")\n",
    "        except Exception as e:\n",
    "            print(f\"tabula extraction failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and filter tables\n",
    "        cleaned_tables = self.clean_and_filter_tables(all_tables)\n",
    "        print(f\"Final count: {len(cleaned_tables)} valid tables\")\n",
    "        \n",
    "        return cleaned_tables\n",
    "    \n",
    "    def clean_and_filter_tables(self, tables: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "        \"\"\"Clean table data and filter out invalid tables\"\"\"\n",
    "        cleaned_tables = []\n",
    "        \n",
    "        for df in tables:\n",
    "            try:\n",
    "                # Remove completely empty rows and columns\n",
    "                df = df.dropna(how='all').dropna(axis=1, how='all')\n",
    "                \n",
    "                # Skip if too small\n",
    "                if df.shape[0] < 2 or df.shape[1] < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Clean column names\n",
    "                df.columns = [str(col).strip().replace('\\n', ' ') for col in df.columns]\n",
    "                \n",
    "                # Clean cell values\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtype == 'object':\n",
    "                        df[col] = df[col].astype(str).str.strip().str.replace('\\n', ' ')\n",
    "                \n",
    "                # Check if table contains financial data\n",
    "                table_text = ' '.join(df.astype(str).values.flatten()).lower()\n",
    "                if any(keyword in table_text for keyword in self.financial_keywords):\n",
    "                    cleaned_tables.append(df)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error cleaning table: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return cleaned_tables\n",
    "    \n",
    "    def categorize_financial_tables(self, tables: List[pd.DataFrame]) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"Categorize tables by financial statement type\"\"\"\n",
    "        categorized = {\n",
    "            \"income_statement\": [],\n",
    "            \"balance_sheet\": [],\n",
    "            \"cash_flow\": [],\n",
    "            \"metrics_and_kpis\": [],\n",
    "            \"other\": []\n",
    "        }\n",
    "        \n",
    "        for i, df in enumerate(tables):\n",
    "            table_text = ' '.join(df.astype(str).values.flatten()).lower()\n",
    "            columns_text = ' '.join(df.columns).lower()\n",
    "            combined_text = table_text + ' ' + columns_text\n",
    "            \n",
    "            # Classification rules\n",
    "            category = \"other\"  # default\n",
    "            \n",
    "            if any(term in combined_text for term in [\n",
    "                'revenue', 'total revenue', 'net income', 'operating income', \n",
    "                'cost of revenue', 'operating expenses', 'income from operations'\n",
    "            ]):\n",
    "                category = \"income_statement\"\n",
    "            \n",
    "            elif any(term in combined_text for term in [\n",
    "                'total assets', 'current assets', 'total liabilities', \n",
    "                'stockholders equity', 'cash and cash equivalents', 'total equity'\n",
    "            ]):\n",
    "                category = \"balance_sheet\"\n",
    "            \n",
    "            elif any(term in combined_text for term in [\n",
    "                'cash flows from operating', 'cash flows from investing',\n",
    "                'cash flows from financing', 'net cash provided', 'operating activities'\n",
    "            ]):\n",
    "                category = \"cash_flow\"\n",
    "            \n",
    "            elif any(term in combined_text for term in [\n",
    "                'monthly active users', 'daily active users', 'average revenue per user',\n",
    "                'family monthly active users', 'family daily active users'\n",
    "            ]):\n",
    "                category = \"metrics_and_kpis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48942bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store table info\n",
    "            table_info = {\n",
    "                \"table_id\": df.attrs.get('table_id', f\"table_{i}\"),\n",
    "                \"data\": df.to_dict('records'),\n",
    "                \"columns\": list(df.columns),\n",
    "                \"shape\": df.shape,\n",
    "                \"extraction_method\": df.attrs.get('extraction_method', 'unknown'),\n",
    "                \"source_page\": df.attrs.get('source_page', 'unknown')\n",
    "            }\n",
    "            \n",
    "            categorized[category].append(table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Print categorization summary\n",
    "        print(\"Table categorization summary:\")\n",
    "        for category, tables_list in categorized.items():\n",
    "            if tables_list:\n",
    "                print(f\"  {category}: {len(tables_list)} tables\")\n",
    "        \n",
    "        return categorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71285c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hybrid Retrieval System\n",
    "class HybridRetriever:\n",
    "    \"\"\"Combines vector search (text) with structured data search\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.text_index = None\n",
    "        self.text_chunks = []\n",
    "        self.structured_data = {}\n",
    "        \n",
    "    def build_text_index(self, chunks: List[Dict]):\n",
    "        \"\"\"Build vector index for text chunks\"\"\"\n",
    "        self.text_chunks = chunks\n",
    "        texts = [chunk[\"content\"] for chunk in chunks]\n",
    "        \n",
    "        print(\"Building text embeddings...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Hybrid Retrieval System\n",
    "class HybridRetriever:\n",
    "    \"\"\"Combines vector search (text) with structured data search\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.text_index = None\n",
    "        self.text_chunks = []\n",
    "        self.structured_data = {}\n",
    "        \n",
    "    def build_text_index(self, chunks: List[Dict]):\n",
    "        \"\"\"Build vector index for text chunks\"\"\"\n",
    "        self.text_chunks = chunks\n",
    "        texts = [chunk[\"content\"] for chunk in chunks]\n",
    "        \n",
    "        print(\"Building text embeddings...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index\n",
    "        dimension = embeddings.shape[1]\n",
    "        self.text_index = faiss.IndexFlatIP(dimension)\n",
    "        faiss.normalize_L2(embeddings)\n",
    "        self.text_index.add(embeddings.astype('float32'))\n",
    "        \n",
    "        print(f\"Text index built with {len(texts)} chunks\")\n",
    "    \n",
    "    def add_structured_data(self, structured_data: Dict[str, List[Dict]]):\n",
    "        \"\"\"Add categorized structured data\"\"\"\n",
    "        self.structured_data = structured_data\n",
    "        total_tables = sum(len(tables) for tables in structured_data.values())\n",
    "        print(f\"Added {total_tables} structured tables to retriever\")\n",
    "    \n",
    "    def search_text(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search text chunks using vector similarity\"\"\"\n",
    "        if self.text_index is None:\n",
    "            return []\n",
    "        \n",
    "        query_embedding = self.model.encode([query])\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        scores, indices = self.text_index.search(query_embedding.astype('float32'), top_k)\n",
    "        \n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if idx != -1:\n",
    "                results.append({\n",
    "                    \"content\": self.text_chunks[idx][\"content\"],\n",
    "                    \"score\": float(score),\n",
    "                    \"chunk_id\": self.text_chunks[idx][\"chunk_id\"],\n",
    "                    \"type\": \"text\"\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def search_structured_data(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search structured data using keyword and semantic matching\"\"\"\n",
    "        results = []\n",
    "        query_lower = query.lower()\n",
    "        query_words = set(query_lower.split())\n",
    "        \n",
    "        # Keywords that suggest specific table types\n",
    "        table_type_hints = {\n",
    "            'income_statement': ['revenue', 'income', 'profit', 'expenses', 'earnings', 'operating'],\n",
    "            'balance_sheet': ['assets', 'liabilities', 'equity', 'balance', 'cash'],\n",
    "            'cash_flow': ['cash flow', 'operating activities', 'investing', 'financing'],\n",
    "            'metrics_and_kpis': ['users', 'active users', 'arpu', 'engagement', 'monthly', 'daily']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd236772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search each category\n",
    "        for category, tables in self.structured_data.items():\n",
    "            category_boost = 1.0\n",
    "            \n",
    "            # Boost score if query suggests this table type\n",
    "            if category in table_type_hints:\n",
    "                if any(hint in query_lower for hint in table_type_hints[category]):\n",
    "                    category_boost = 1.5\n",
    "            \n",
    "            for table in tables:\n",
    "                # Search in columns and data\n",
    "                columns_text = ' '.join(table['columns']).lower()\n",
    "                data_text = json.dumps(table['data']).lower()\n",
    "                combined_text = columns_text + ' ' + data_text\n",
    "                \n",
    "                # Calculate relevance score\n",
    "                relevance_score = self._calculate_relevance(query_words, combined_text)\n",
    "                relevance_score *= category_boost\n",
    "                \n",
    "                if relevance_score > 0:\n",
    "                    results.append({\n",
    "                        \"category\": category,\n",
    "                        \"table_id\": table['table_id'],\n",
    "                        \"data\": table['data'][:5],  # Limit rows for context\n",
    "                        \"columns\": table['columns'],\n",
    "                        \"shape\": table['shape'],\n",
    "                        \"score\": relevance_score,\n",
    "                        \"type\": \"structured\",\n",
    "                        \"source_page\": table.get('source_page', 'unknown')\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by relevance and return top-k\n",
    "        results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        return results[:top_k]\n",
    "    \n",
    "    def _calculate_relevance(self, query_words: set, text: str) -> float:\n",
    "        \"\"\"Calculate relevance score between query and text\"\"\"\n",
    "        text_words = set(text.split())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13924cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact matches\n",
    "        exact_matches = len(query_words & text_words)\n",
    "        \n",
    "        # Partial matches (substring matching)\n",
    "        partial_matches = 0\n",
    "        for query_word in query_words:\n",
    "            if any(query_word in text_word for text_word in text_words):\n",
    "                partial_matches += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by query length\n",
    "        total_score = (exact_matches + partial_matches) / len(query_words)\n",
    "        return total_score\n",
    "    \n",
    "    def hybrid_retrieve(self, query: str, text_k: int = 3, struct_k: int = 2) -> Dict[str, List]:\n",
    "        \"\"\"Perform hybrid retrieval combining text and structured search\"\"\"\n",
    "        print(f\"Hybrid search for: '{query}'\")\n",
    "        \n",
    "        # Search text chunks\n",
    "        text_results = self.search_text(query, top_k=text_k)\n",
    "        print(f\"Found {len(text_results)} relevant text chunks\")\n",
    "        \n",
    "        # Search structured data\n",
    "        structured_results = self.search_structured_data(query, top_k=struct_k)\n",
    "        print(f\"Found {len(structured_results)} relevant tables\")\n",
    "        \n",
    "        return {\n",
    "            \"text_context\": text_results,\n",
    "            \"structured_data\": structured_results\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Enhanced Answer Generator\n",
    "class HybridQAGenerator:\n",
    "    \"\"\"Generate answers using both text and structured context\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_hybrid_answer(self, query: str, text_context: List[Dict], \n",
    "                             structured_data: List[Dict]) -> Dict:\n",
    "        \"\"\"Generate answer using both text and structured context\"\"\"\n",
    "        \n",
    "        # Prepare text context\n",
    "        text_content = \"\"\n",
    "        if text_context:\n",
    "            text_content = \"\\n\\n\".join([\n",
    "                f\"Text Context {i+1}: {chunk['content']}\"\n",
    "                for i, chunk in enumerate(text_context)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1dfb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare structured context\n",
    "        structured_content = \"\"\n",
    "        if structured_data:\n",
    "            for i, table in enumerate(structured_data):\n",
    "                structured_content += f\"\\n\\nTable {i+1} ({table['category']}):\\n\"\n",
    "                structured_content += f\"Source: Page {table['source_page']}\\n\"\n",
    "                structured_content += f\"Columns: {', '.join(table['columns'])}\\n\"\n",
    "                structured_content += \"Data rows:\\n\"\n",
    "                \n",
    "                for j, row in enumerate(table['data'][:3], 1):\n",
    "                    row_str = ', '.join([f\"{k}: {v}\" for k, v in row.items() if v])\n",
    "                    structured_content += f\"  Row {j}: {row_str}\\n\"\n",
    "                \n",
    "                if len(table['data']) > 3:\n",
    "                    structured_content += f\"  ... ({len(table['data']) - 3} more rows)\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive prompt\n",
    "        prompt = f\"\"\"As a financial analyst, answer the following query using the provided context from Meta's financial reports.\n",
    "\n",
    "QUERY: {query}\n",
    "\n",
    "TEXT CONTEXT:\n",
    "{text_content if text_content else \"No relevant text context found.\"}\n",
    "\n",
    "STRUCTURED DATA (TABLES):\n",
    "{structured_content if structured_content else \"No relevant structured data found.\"}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Provide a direct, factual answer based on the available context\n",
    "- When using numerical data, cite specific figures from the structured data\n",
    "- If comparing periods, use the structured data for precise comparisons\n",
    "- If information is not available in the context, state this clearly\n",
    "- Format financial figures clearly (e.g., $36.5 billion, 12.3% increase)\n",
    "- Be concise but comprehensive\n",
    "\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a financial analyst expert in interpreting financial statements and reports. Provide accurate, data-driven answers.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=700,\n",
    "                temperature=0.1,\n",
    "                presence_penalty=0.1\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"answer\": response.choices[0].message.content,\n",
    "                \"tokens_used\": response.usage.total_tokens,\n",
    "                \"text_sources\": len(text_context),\n",
    "                \"table_sources\": len(structured_data),\n",
    "                \"model_used\": self.model\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"answer\": f\"Error generating response: {str(e)}\",\n",
    "                \"tokens_used\": 0,\n",
    "                \"text_sources\": len(text_context),\n",
    "                \"table_sources\": len(structured_data),\n",
    "                \"model_used\": self.model\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6651a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Main Pipeline for Step 2\n",
    "def run_hybrid_rag_pipeline():\n",
    "    \"\"\"Execute the complete hybrid RAG pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"STEP 2: HYBRID RAG WITH STRUCTURED DATA INTEGRATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # File path\n",
    "    pdf_path = \"meta_q1_2024.pdf\"  # Update this path\n",
    "    \n",
    "    # Initialize all components\n",
    "    print(\"\\n1. Initializing components...\")\n",
    "    pdf_processor = PDFProcessor()  # From Step 1\n",
    "    struct_processor = StructuredDataProcessor()\n",
    "    hybrid_retriever = HybridRetriever()\n",
    "    hybrid_generator = HybridQAGenerator()\n",
    "    \n",
    "    # Process document\n",
    "    print(\"\\n2. Processing PDF document...\")\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"ERROR: PDF file not found at {pdf_path}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text and tables\n",
    "    raw_text = pdf_processor.extract_text_from_pdf(pdf_path)\n",
    "    text_chunks = pdf_processor.chunk_text(raw_text)\n",
    "    \n",
    "    print(\"\\n3. Extracting structured data (tables)...\")\n",
    "    tables = struct_processor.extract_tables_from_pdf(pdf_path)\n",
    "    structured_data = struct_processor.categorize_financial_tables(tables)\n",
    "    \n",
    "    # Build hybrid retrieval system\n",
    "    print(\"\\n4. Building hybrid retrieval system...\")\n",
    "    hybrid_retriever.build_text_index(text_chunks)\n",
    "    hybrid_retriever.add_structured_data(structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries for Step 2\n",
    "    test_queries = [\n",
    "        \"What was Meta's net income in Q1 2024 compared to Q1 2023?\",\n",
    "        \"Summarize Meta's operating expenses in Q1 2024.\",\n",
    "        \"How many monthly active users did Meta have in Q1 2024?\",\n",
    "        \"What was Meta's revenue growth rate in Q1 2024?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n5. Testing hybrid RAG pipeline...\")\n",
    "    results = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"QUERY: {query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hybrid retrieval\n",
    "        hybrid_results = hybrid_retriever.hybrid_retrieve(query, text_k=3, struct_k=2)\n",
    "        \n",
    "        # Display retrieved context\n",
    "        print(\"\\nRETRIEVED TEXT CONTEXT:\")\n",
    "        for i, chunk in enumerate(hybrid_results[\"text_context\"], 1):\n",
    "            print(f\"Text {i} (Score: {chunk['score']:.3f}): {chunk['content'][:150]}...\")\n",
    "        \n",
    "        print(\"\\nRETRIEVED STRUCTURED DATA:\")\n",
    "        for i, table in enumerate(hybrid_results[\"structured_data\"], 1):\n",
    "            print(f\"Table {i} ({table['category']}) - Score: {table['score']:.3f}\")\n",
    "            print(f\"  Shape: {table['shape']}, Source: Page {table['source_page']}\")\n",
    "            print(f\"  Columns: {', '.join(table['columns'][:4])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c536efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answer\n",
    "        print(\"\\nGENERATING HYBRID ANSWER...\")\n",
    "        answer_result = hybrid_generator.generate_hybrid_answer(\n",
    "            query,\n",
    "            hybrid_results[\"text_context\"],\n",
    "            hybrid_results[\"structured_data\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFINAL ANSWER:\")\n",
    "        print(f\"{answer_result['answer']}\")\n",
    "        \n",
    "        print(f\"\\nMETADATA:\")\n",
    "        print(f\"- Tokens used: {answer_result['tokens_used']}\")\n",
    "        print(f\"- Text sources: {answer_result['text_sources']}\")\n",
    "        print(f\"- Table sources: {answer_result['table_sources']}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[query] = {\n",
    "            \"answer\": answer_result['answer'],\n",
    "            \"text_context\": hybrid_results[\"text_context\"],\n",
    "            \"structured_data\": hybrid_results[\"structured_data\"],\n",
    "            \"metadata\": answer_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "    print(\"\\n6. Saving results...\")\n",
    "    output_file = \"step2_hybrid_rag_results.json\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Results saved to: {output_file}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"HYBRID RAG PIPELINE SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Text chunks processed: {len(text_chunks)}\")\n",
    "    print(f\"Tables extracted: {len(tables)}\")\n",
    "    print(f\"Queries processed: {len(test_queries)}\")\n",
    "    \n",
    "    # Category breakdown\n",
    "    for category, tables_list in structured_data.items():\n",
    "        if tables_list:\n",
    "            print(f\"{category}: {len(tables_list)} tables\")\n",
    "    \n",
    "    return results, structured_data\n",
    "\n",
    "#%% Execute Pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the hybrid pipeline\n",
    "    results, structured_data = run_hybrid_rag_pipeline()\n",
    "\n",
    "#%% Evaluation for Step 2\n",
    "def evaluate_hybrid_rag(results: Dict, structured_data: Dict):\n",
    "    \"\"\"Evaluate the hybrid RAG system performance\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STEP 2 EVALUATION: HYBRID RAG PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Quantitative metrics\n",
    "    total_tokens = sum([r['metadata']['tokens_used'] for r in results.values()])\n",
    "    avg_text_sources = np.mean([r['metadata']['text_sources'] for r in results.values()])\n",
    "    avg_table_sources = np.mean([r['metadata']['table_sources'] for r in results.values()])\n",
    "    \n",
    "    print(\"Quantitative Metrics:\")\n",
    "    print(f\"  Total tokens used: {total_tokens}\")\n",
    "    print(f\"  Average text sources per query: {avg_text_sources:.1f}\")\n",
    "    print(f\"  Average table sources per query: {avg_table_sources:.1f}\")\n",
    "    \n",
    "    # Structured data utilization\n",
    "    print(f\"\\nStructured Data Utilization:\")\n",
    "    total_tables = sum(len(tables) for tables in structured_data.values())\n",
    "    print(f\"  Total tables available: {total_tables}\")\n",
    "    \n",
    "    queries_using_tables = sum(1 for r in results.values() if r['metadata']['table_sources'] > 0)\n",
    "    print(f\"  Queries using tables: {queries_using_tables}/{len(results)}\")\n",
    "    \n",
    "    # Answer quality indicators\n",
    "    print(f\"\\nAnswer Quality Indicators:\")\n",
    "    for query, result in results.items():\n",
    "        answer = result['answer']\n",
    "        \n",
    "        # Check for numerical data\n",
    "        has_numbers = bool(re.search(r'\\$[\\d,\\.]+[MB]?|\\d+%|\\d+\\.\\d+%', answer))\n",
    "        has_comparison = any(word in answer.lower() for word in ['compared', 'versus', 'increased', 'decreased', 'growth'])\n",
    "        answer_length = len(answer.split())\n",
    "        \n",
    "        print(f\"\\n  Query: {query[:50]}...\")\n",
    "        print(f\"    Contains financial figures: {has_numbers}\")\n",
    "        print(f\"    Contains comparisons: {has_comparison}\")\n",
    "        print(f\"    Answer length: {answer_length} words\")\n",
    "        print(f\"    Used {result['metadata']['table_sources']} tables, {result['metadata']['text_sources']} text chunks\")\n",
    "\n",
    "# Run evaluation\n",
    "if 'results' in globals() and 'structured_data' in globals():\n",
    "    evaluate_hybrid_rag(results, structured_data)\n",
    "\n",
    "#%% Additional Analysis: Table Content Preview\n",
    "def preview_extracted_tables(structured_data: Dict):\n",
    "    \"\"\"Preview the content of extracted tables\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXTRACTED TABLES PREVIEW\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for category, tables in structured_data.items():\n",
    "        if tables:\n",
    "            print(f\"\\n{category.upper()} ({len(tables)} tables):\")\n",
    "            \n",
    "            for i, table in enumerate(tables[:2], 1):  # Show first 2 tables per category\n",
    "                print(f\"\\n  Table {i} (ID: {table['table_id']}):\")\n",
    "                print(f\"    Shape: {table['shape']}\")\n",
    "                print(f\"    Columns: {', '.join(table['columns'])}\")\n",
    "                \n",
    "                # Show first few data rows\n",
    "                print(f\"    Sample data:\")\n",
    "                for j, row in enumerate(table['data'][:3], 1):\n",
    "                    row_preview = {k: str(v)[:30] + '...' if len(str(v)) > 30 else v \n",
    "                                 for k, v in row.items()}\n",
    "                    print(f\"      Row {j}: {row_preview}\")\n",
    "\n",
    "# Preview tables if available\n",
    "if 'structured_data' in globals():\n",
    "    preview_extracted_tables(structured_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
